INFO main org.apache.spark.scheduler.DAGScheduler - Job 1 failed: take at Oracle2Hbase.scala:76, took 1.565542 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@6c15e8c7{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@ef1695a{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@238bfd6c{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@319c3a25{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-1 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-57ea5bad-543f-41b8-b6b5-01588f066e4b
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 57551.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-be72392c-c0c5-4eae-8c06-a6ab3faa9c48
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4625ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@6c15e8c7{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4767ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57572.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:57572
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 57572, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:57572 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 57572, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 57572, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 57572, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65ddee5a{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a0f2853{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70c69586{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e0fbeb5{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2676dc05{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b1dc579{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 376.581983 ms
 INFO main org.apache.spark.SparkContext - Starting job: collect at Oracle2Hbase.scala:68
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at Oracle2Hbase.scala:68) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:57572 (size: 4.2 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5807 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.storage.memory.MemoryStore - Block taskresult_0 stored as bytes in memory (estimated size 18.7 MB, free 879.8 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added taskresult_0 in memory on 10.0.1.32:57572 (size: 18.7 MB, free: 879.8 MB)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 19609878 bytes result sent via BlockManager)
 INFO task-result-getter-0 org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /10.0.1.32:57572 after 23 ms (0 ms spent in bootstraps)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 5026 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (collect at Oracle2Hbase.scala:68) finished in 5.051 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at Oracle2Hbase.scala:68, took 5.237882 s
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Removed taskresult_0 on 10.0.1.32:57572 in memory (size: 18.7 MB, free: 898.5 MB)
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 17.470149 ms
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:57572 in memory (size: 4.2 KB, free: 898.5 MB)
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 57660.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-3eef2274-1454-42d3-b78f-b7bceec97454
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @5088ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@6b3f6585{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5223ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57681.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:57681
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 57681, None)
 INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:57681 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 57681, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 57681, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 57681, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6dab01d9{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@dd2856e{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b1dc579{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@338766de{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4976085{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f631ca0{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 323.744714 ms
 INFO main org.apache.spark.SparkContext - Starting job: collect at Oracle2Hbase.scala:68
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at Oracle2Hbase.scala:68) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:57681 (size: 4.2 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5807 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.storage.memory.MemoryStore - Block taskresult_0 stored as bytes in memory (estimated size 18.7 MB, free 879.8 MB)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Added taskresult_0 in memory on 10.0.1.32:57681 (size: 18.7 MB, free: 879.8 MB)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 19609878 bytes result sent via BlockManager)
 INFO task-result-getter-0 org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /10.0.1.32:57681 after 30 ms (0 ms spent in bootstraps)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 5320 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (collect at Oracle2Hbase.scala:68) finished in 5.342 s
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Removed taskresult_0 on 10.0.1.32:57681 in memory (size: 18.7 MB, free: 898.5 MB)
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at Oracle2Hbase.scala:68, took 5.511920 s
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 22.07434 ms
 INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:57681 in memory (size: 4.2 KB, free: 898.5 MB)
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 57740.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-505a73f9-db80-40d3-8794-df3d075c736d
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4838ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@6b3f6585{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4980ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57761.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:57761
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 57761, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:57761 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 57761, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 57761, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 57761, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43fda8d9{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@15efda6c{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@33f2df51{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@404eca05{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@61a91c9b{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f40c00{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 328.008716 ms
 INFO main org.apache.spark.SparkContext - Starting job: collect at Oracle2Hbase.scala:68
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at Oracle2Hbase.scala:68) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:57761 (size: 4.2 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5807 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.storage.memory.MemoryStore - Block taskresult_0 stored as bytes in memory (estimated size 18.7 MB, free 879.8 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added taskresult_0 in memory on 10.0.1.32:57761 (size: 18.7 MB, free: 879.8 MB)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 19609878 bytes result sent via BlockManager)
 INFO task-result-getter-0 org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /10.0.1.32:57761 after 50 ms (0 ms spent in bootstraps)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 5312 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Removed taskresult_0 on 10.0.1.32:57761 in memory (size: 18.7 MB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (collect at Oracle2Hbase.scala:68) finished in 5.332 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at Oracle2Hbase.scala:68, took 5.551338 s
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:57761 in memory (size: 4.2 KB, free: 898.5 MB)
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.083306 ms
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 57837.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-31865f75-e53e-45cf-bf05-962eed4cdabb
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4642ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@4c560aee{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4828ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57858.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:57858
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 57858, None)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:57858 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 57858, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 57858, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 57858, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6242ae3b{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@696b4a95{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d68b571{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@330c1f61{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@15efda6c{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@404eca05{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 404.262974 ms
 INFO main org.apache.spark.SparkContext - Starting job: collect at Oracle2Hbase.scala:68
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at Oracle2Hbase.scala:68) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:57858 (size: 4.2 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5807 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 57890.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-f3c799a6-5399-48dd-bfb2-8fca3d268deb
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4590ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@6c15e8c7{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4730ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57911.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:57911
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 57911, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:57911 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 57911, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 57911, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 57911, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c447c09{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4694f434{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@dd2856e{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77f905e3{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@338766de{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1192b58e{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 485.274767 ms
 INFO main org.apache.spark.SparkContext - Starting job: collect at Oracle2Hbase.scala:68
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at Oracle2Hbase.scala:68) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:57911 (size: 4.2 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5807 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.storage.memory.MemoryStore - Block taskresult_0 stored as bytes in memory (estimated size 18.7 MB, free 879.8 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added taskresult_0 in memory on 10.0.1.32:57911 (size: 18.7 MB, free: 879.8 MB)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 19609878 bytes result sent via BlockManager)
 INFO task-result-getter-0 org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /10.0.1.32:57911 after 28 ms (0 ms spent in bootstraps)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 5795 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (collect at Oracle2Hbase.scala:68) finished in 5.821 s
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Removed taskresult_0 on 10.0.1.32:57911 in memory (size: 18.7 MB, free: 898.5 MB)
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at Oracle2Hbase.scala:68, took 6.041131 s
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:57911 in memory (size: 4.2 KB, free: 898.5 MB)
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 24.446315 ms
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 58053.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-35348dc0-1253-4355-ae84-77b1479a268b
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4662ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@6b3f6585{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4800ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58074.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:58074
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 58074, None)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:58074 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 58074, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 58074, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 58074, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3ae126d1{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f860823{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6c1cfa53{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6232ffdb{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37d28f02{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f9f3928{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 362.042542 ms
 INFO main org.apache.spark.SparkContext - Starting job: collect at Oracle2Hbase.scala:68
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at Oracle2Hbase.scala:68) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:58074 (size: 4.2 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at collect at Oracle2Hbase.scala:68)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5807 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.storage.memory.MemoryStore - Block taskresult_0 stored as bytes in memory (estimated size 18.7 MB, free 879.8 MB)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Added taskresult_0 in memory on 10.0.1.32:58074 (size: 18.7 MB, free: 879.8 MB)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 19609878 bytes result sent via BlockManager)
 INFO task-result-getter-0 org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /10.0.1.32:58074 after 27 ms (0 ms spent in bootstraps)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 5991 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Removed taskresult_0 on 10.0.1.32:58074 in memory (size: 18.7 MB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (collect at Oracle2Hbase.scala:68) finished in 6.020 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at Oracle2Hbase.scala:68, took 6.174902 s
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 25.418892 ms
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:58074 in memory (size: 4.2 KB, free: 898.5 MB)
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@6b3f6585{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-1 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-be535ba4-2e6d-4503-ab58-6fa93e56dad4
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 58332.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-cf00b41f-27b7-4132-bb68-2a719fab3895
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4643ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@6c15e8c7{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4786ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58353.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:58353
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 58353, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:58353 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 58353, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 58353, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 58353, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65ddee5a{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52b06bef{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6af91cc8{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6056232d{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@107bfcb2{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@17092fff{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 473.282378 ms
 INFO main org.apache.spark.SparkContext - Starting job: take at Oracle2Hbase.scala:52
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (take at Oracle2Hbase.scala:52) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (take at Oracle2Hbase.scala:52)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[3] at take at Oracle2Hbase.scala:52), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.5 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 898.5 MB)
 INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:58353 (size: 4.2 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at take at Oracle2Hbase.scala:52)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5723 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2713 bytes result sent to driver
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 266 ms on localhost (executor driver) (1/1)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (take at Oracle2Hbase.scala:52) finished in 0.287 s
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: take at Oracle2Hbase.scala:52, took 0.577866 s
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 25.890691 ms
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@6c15e8c7{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@ef1695a{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@238bfd6c{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@319c3a25{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-1dfaebfe-c8ac-4b28-b0e4-97b89a76be27
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 58393.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-04b4c3e7-1013-44f9-af98-fc0519b4e8ea
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4786ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@6c15e8c7{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4929ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58414.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:58414
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 58414, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:58414 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 58414, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 58414, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 58414, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65ddee5a{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@61bcbcce{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6232ffdb{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@33f2df51{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bac686b{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2121d1f9{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 282.549985 ms
 INFO main org.apache.spark.SparkContext - Starting job: collect at Oracle2Hbase.scala:52
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at Oracle2Hbase.scala:52) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (collect at Oracle2Hbase.scala:52)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at Oracle2Hbase.scala:52), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:58414 (size: 4.2 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at Oracle2Hbase.scala:52)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5807 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.storage.memory.MemoryStore - Block taskresult_0 stored as bytes in memory (estimated size 18.7 MB, free 879.8 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added taskresult_0 in memory on 10.0.1.32:58414 (size: 18.7 MB, free: 879.8 MB)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 19609878 bytes result sent via BlockManager)
 INFO task-result-getter-0 org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /10.0.1.32:58414 after 24 ms (0 ms spent in bootstraps)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 5321 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Removed taskresult_0 on 10.0.1.32:58414 in memory (size: 18.7 MB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (collect at Oracle2Hbase.scala:52) finished in 5.348 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at Oracle2Hbase.scala:52, took 5.531773 s
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:58414 in memory (size: 4.2 KB, free: 898.5 MB)
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.129143 ms
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@6c15e8c7{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@ef1695a{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@238bfd6c{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@319c3a25{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-1 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-64607dbd-0348-4725-b7f3-54013fb608ba
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 58846.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-63d1b30b-278a-491c-bd95-3a98ef72d23d
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4880ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@45e1aa48{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5024ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58867.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:58867
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 58867, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:58867 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 58867, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 58867, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 58867, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a87026{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@33f2df51{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bac686b{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@61a91c9b{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2121d1f9{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52d6d273{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 336.867248 ms
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:77
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsHadoopDataset at Oracle2Hbase.scala:77) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:77)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[6] at map at Oracle2Hbase.scala:72), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 98.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.9 KB, free 898.4 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:58867 (size: 38.9 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at Oracle2Hbase.scala:72)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5790 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 18.937465 ms
 INFO Executor task launch worker for task 0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 0
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:77) failed in 0.482 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 failed: saveAsHadoopDataset at Oracle2Hbase.scala:77, took 0.707503 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@45e1aa48{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-aa52f84b-07a3-4c2a-beeb-c28b0b0e7589
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 58953.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-ea57edf0-c674-4e9e-bfd5-ba09b45e8bf4
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4327ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4468ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58974.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:58974
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 58974, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:58974 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 58974, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 58974, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 58974, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b76aa5a{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@777d191f{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@31142d58{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1697f2b3{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3134153d{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@659feb22{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-53168e63-ee63-43f8-a27d-0f5b44a00d5c
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 59048.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-fb4b6768-bf6c-4f3c-bfee-a37035949ae1
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4422ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4563ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59069.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:59069
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 59069, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:59069 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 59069, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 59069, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 59069, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@770beef5{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73809e7{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48df4071{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@692dba54{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f14761c{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ff19c33{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 378.415147 ms
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:77
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsHadoopDataset at Oracle2Hbase.scala:77) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:77)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[6] at map at Oracle2Hbase.scala:72), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 98.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.9 KB, free 898.4 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:59069 (size: 38.9 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at Oracle2Hbase.scala:72)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5790 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 17.425173 ms
 INFO Executor task launch worker for task 0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 0
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:77) failed in 0.442 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 failed: saveAsHadoopDataset at Oracle2Hbase.scala:77, took 0.667289 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-93c6f051-3882-410d-af79-f4b91db58d5d
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 59228.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-371454ef-67f8-4046-9c31-9ee64c9b82bf
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4771ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4920ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59249.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:59249
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 59249, None)
 INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:59249 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 59249, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 59249, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 59249, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43fda8d9{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@330c1f61{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@15efda6c{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ab26378{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@404eca05{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@462e1e64{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 371.327295 ms
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:80
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsHadoopDataset at Oracle2Hbase.scala:80) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:80)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[6] at map at Oracle2Hbase.scala:75), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 98.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.9 KB, free 898.4 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:59249 (size: 38.9 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at Oracle2Hbase.scala:75)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5790 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 47.204659 ms
 INFO Executor task launch worker for task 0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 0
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:80) failed in 0.596 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 failed: saveAsHadoopDataset at Oracle2Hbase.scala:80, took 0.882560 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-0 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-0e47e178-0725-426e-9351-fc97113e325f
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 59798.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-579398a8-d903-4e74-9c63-c8d039c4ec01
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4699ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4846ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59820.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:59820
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 59820, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:59820 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 59820, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 59820, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 59820, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e1fc42f{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e642ee1{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd954f{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6dc1dc69{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19e0dffe{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4694f434{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 360.867724 ms
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:93
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsHadoopDataset at Oracle2Hbase.scala:93) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:93)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:88), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 99.2 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:59820 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:88)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5790 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.789948 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.473334 ms
 INFO Executor task launch worker for task 0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 0
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:93) failed in 0.525 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 failed: saveAsHadoopDataset at Oracle2Hbase.scala:93, took 0.751135 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-3a8808e7-e69c-49e3-b5bf-5b040d22bafd
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 59889.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-eebd3943-cfa7-4aab-abe9-c356ee256e6b
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4850ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4993ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59910.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:59910
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 59910, None)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:59910 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 59910, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 59910, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 59910, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e1fc42f{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@dd2856e{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b1dc579{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@338766de{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4976085{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f631ca0{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT_20140101 where icd_code is not null and diagnosis is null
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-3 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-66751d8e-52d4-4a99-b394-4fe18817ef39
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 59941.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-9832be1a-a716-4fa5-bd72-15019516173e
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4808ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4965ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59962.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:59962
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 59962, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:59962 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 59962, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 59962, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 59962, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e1fc42f{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@dd2856e{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b1dc579{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@338766de{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4976085{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f631ca0{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 300.285464 ms
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:94
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsHadoopDataset at Oracle2Hbase.scala:94) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:94)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 99.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:59962 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5790 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 54.674056 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.562291 ms
 INFO Executor task launch worker for task 0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 0
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:94) failed in 0.872 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 failed: saveAsHadoopDataset at Oracle2Hbase.scala:94, took 1.083794 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-50a1bb89-7159-4c6f-9c6e-383b446b046b
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60004.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-276a0a0d-0f8e-48e0-994e-ac5a78a80925
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4695ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@6b3f6585{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4879ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60025.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:60025
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 60025, None)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:60025 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 60025, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 60025, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 60025, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6dab01d9{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7e9f2c32{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5d4e13e1{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4833eff3{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56928e17{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@221a2068{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@6b3f6585{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-3 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-0fd0b7b9-ee4c-45a5-bb85-eec7cbcb8779
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60063.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-69bac4d6-f32b-42cb-a9c9-560d60d8de35
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4915ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55d9b8f0{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a518813{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43d38654{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75361cf6{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@39c385d6{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5063ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60073.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:60073
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 60073, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:60073 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 60073, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 60073, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 60073, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@600f5704{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd954f{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a0f2853{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19e0dffe{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e0fbeb5{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@dd2856e{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@39c385d6{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@75361cf6{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@43d38654{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@a518813{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55d9b8f0{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-e2d4a308-9b7d-42c5-88fe-554106a67eb9
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60112.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-3cd94cca-b307-40e4-9110-e2046a1b7a27
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4644ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@6b3f6585{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4802ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60133.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:60133
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 60133, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:60133 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 60133, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 60133, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 60133, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43fda8d9{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6232ffdb{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37d28f02{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bac686b{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f9f3928{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1806bc4c{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 384.257849 ms
 INFO main org.apache.spark.SparkContext - Starting job: collect at Oracle2Hbase.scala:70
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at Oracle2Hbase.scala:70) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (collect at Oracle2Hbase.scala:70)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at Oracle2Hbase.scala:70), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 11.0 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.5 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:60133 (size: 5.5 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at Oracle2Hbase.scala:70)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5807 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 54662 bytes result sent to driver
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1018 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (collect at Oracle2Hbase.scala:70) finished in 1.037 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at Oracle2Hbase.scala:70, took 1.197363 s
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 30.999583 ms
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@6b3f6585{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-33e72169-fe86-44d1-ae41-50a43c16ed1e
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60477.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-45821c87-c308-4b86-93b9-e4f91edcd7b9
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4810ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4952ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60498.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:60498
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 60498, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:60498 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 60498, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 60498, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 60498, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b5c4f17{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1e60b459{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e906375{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2489e84a{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62b93086{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1eff3cfb{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT_20140101 where icd_code is not null and diagnosis is null
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-4d793e3a-b64d-4857-a6e8-3bf6437eb57c
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60553.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-1e464aa7-d040-4feb-9ed3-ab09f174abc8
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4822ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4970ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60574.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:60574
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 60574, None)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:60574 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 60574, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 60574, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 60574, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e1fc42f{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56928e17{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a49af50{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@221a2068{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b7eac14{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4f8d86e4{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 344.297102 ms
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:93
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsHadoopDataset at Oracle2Hbase.scala:93) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:93)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:88), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 99.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:60574 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:88)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5790 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 24.774432 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.373812 ms
 INFO Executor task launch worker for task 0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 0
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:93) failed in 1.322 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 failed: saveAsHadoopDataset at Oracle2Hbase.scala:93, took 1.526894 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-3 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-b2575437-3694-4e22-b1d6-3265b4b3f654
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60689.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-6d243333-204c-4229-87e1-c734ad45b051
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @5388ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5553ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60710.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:60710
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 60710, None)
 INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:60710 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 60710, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 60710, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 60710, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@600f5704{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2676dc05{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4833eff3{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b1dc579{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60dd0587{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7fc420b8{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 323.207412 ms
 INFO main org.apache.spark.SparkContext - Starting job: foreach at Oracle2Hbase.scala:95
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (foreach at Oracle2Hbase.scala:95) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (foreach at Oracle2Hbase.scala:95)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 12.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.5 KB, free 898.5 MB)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:60710 (size: 6.5 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5778 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 26.36581 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.849972 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1374 bytes result sent to driver
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1774 ms on localhost (executor driver) (1/1)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (foreach at Oracle2Hbase.scala:95) finished in 1.791 s
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: foreach at Oracle2Hbase.scala:95, took 2.047288 s
 INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:60710 in memory (size: 6.5 KB, free: 898.5 MB)
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:102
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsHadoopDataset at Oracle2Hbase.scala:102) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:102)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 99.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 10.0.1.32:60710 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5791 bytes)
 INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
 INFO Executor task launch worker for task 1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 1 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 1 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 1.0 (TID 1)
 java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 1.0 failed 1 times; aborting job
 INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 1
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:102) failed in 0.802 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 1 failed: saveAsHadoopDataset at Oracle2Hbase.scala:102, took 0.869163 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-0 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-e79e6467-ce60-4685-b23d-9825dd1cd663
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60787.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-5b34fbe1-8143-4d71-a04c-8ff2c9a31c1b
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4963ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5118ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60808.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:60808
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 60808, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:60808 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 60808, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 60808, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 60808, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@28bdbe88{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e0fbeb5{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2676dc05{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@dd2856e{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b1dc579{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4976085{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 300.574339 ms
 INFO main org.apache.spark.SparkContext - Starting job: foreach at Oracle2Hbase.scala:95
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (foreach at Oracle2Hbase.scala:95) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (foreach at Oracle2Hbase.scala:95)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 12.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.5 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:60808 (size: 6.5 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5778 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 35.147974 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.802054 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1374 bytes result sent to driver
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1540 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (foreach at Oracle2Hbase.scala:95) finished in 1.560 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: foreach at Oracle2Hbase.scala:95, took 1.840745 s
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:60808 in memory (size: 6.5 KB, free: 898.5 MB)
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:102
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsHadoopDataset at Oracle2Hbase.scala:102) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:102)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 99.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 10.0.1.32:60808 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5791 bytes)
 INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
 INFO Executor task launch worker for task 1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 1 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 1 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 1.0 (TID 1)
 java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 1.0 failed 1 times; aborting job
 INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 1
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:102) failed in 0.596 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 1 failed: saveAsHadoopDataset at Oracle2Hbase.scala:102, took 0.639400 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-1 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-6a93b52f-3742-4254-bd54-c91f44f1e803
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 60946.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-a155e478-7822-42f5-b1c6-94008a02eb15
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4447ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4601ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60967.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:60967
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 60967, None)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:60967 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 60967, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 60967, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 60967, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@600f5704{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2676dc05{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4833eff3{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b1dc579{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60dd0587{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7fc420b8{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 414.341906 ms
 INFO main org.apache.spark.SparkContext - Starting job: foreach at Oracle2Hbase.scala:95
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (foreach at Oracle2Hbase.scala:95) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (foreach at Oracle2Hbase.scala:95)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 12.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.5 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:60967 (size: 6.5 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5778 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 23.042087 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.192988 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1461 bytes result sent to driver
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1671 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (foreach at Oracle2Hbase.scala:95) finished in 1.695 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: foreach at Oracle2Hbase.scala:95, took 1.944689 s
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:60967 in memory (size: 6.5 KB, free: 898.5 MB)
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:103
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsHadoopDataset at Oracle2Hbase.scala:103) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:103)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 99.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 10.0.1.32:60967 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5791 bytes)
 INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
 INFO Executor task launch worker for task 1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 1 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 1 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 1.0 (TID 1)
 java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 1.0 failed 1 times; aborting job
 INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 1
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:103) failed in 1.029 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.IllegalArgumentException: Table qualifier must not be empty
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:179)
	at org.apache.hadoop.hbase.TableName.isLegalTableQualifierName(TableName.java:149)
	at org.apache.hadoop.hbase.TableName.<init>(TableName.java:322)
	at org.apache.hadoop.hbase.TableName.createTableNameIfNecessary(TableName.java:358)
	at org.apache.hadoop.hbase.TableName.valueOf(TableName.java:445)
	at org.apache.hadoop.hbase.mapred.TableOutputFormat.getRecordWriter(TableOutputFormat.java:79)
	at org.apache.spark.SparkHadoopWriter.open(SparkHadoopWriter.scala:90)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1206)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1197)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 1 failed: saveAsHadoopDataset at Oracle2Hbase.scala:103, took 1.063969 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-1 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-1b798a6f-550a-4cce-bc1d-d0f20d51f685
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61209.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-dfe7a437-d1ab-47b4-b1a4-ce0794921715
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4748ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@242a209e{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4904ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61231.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:61231
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 61231, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:61231 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 61231, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 61231, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 61231, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@606f81b5{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bac686b{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f9f3928{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2121d1f9{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1806bc4c{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f9a4401{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 350.051059 ms
 INFO main org.apache.spark.SparkContext - Starting job: foreach at Oracle2Hbase.scala:95
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (foreach at Oracle2Hbase.scala:95) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (foreach at Oracle2Hbase.scala:95)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 12.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.5 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:61231 (size: 6.5 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5778 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.102021 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.105373 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1374 bytes result sent to driver
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1330 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (foreach at Oracle2Hbase.scala:95) finished in 1.348 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: foreach at Oracle2Hbase.scala:95, took 1.644324 s
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:61231 in memory (size: 6.5 KB, free: 898.5 MB)
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:103
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsHadoopDataset at Oracle2Hbase.scala:103) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:103)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 99.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 10.0.1.32:61231 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:89)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5791 bytes)
 INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
 INFO Executor task launch worker for task 1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 1 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x856540d connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x856540d0x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 1-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.85/192.168.14.85:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 1-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.85/192.168.14.85:2181, initiating session
 INFO Executor task launch worker for task 1-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.85/192.168.14.85:2181, sessionid = 0x35d5d920e9300f4, negotiated timeout = 60000
 INFO Executor task launch worker for task 1 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 1 org.apache.spark.mapred.SparkHadoopMapRedUtil - No need to commit output of task because needsTaskCommit=false: attempt_20170727164821_0001_m_000000_1
 INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1459 bytes result sent to driver
 INFO task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 3461 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:103) finished in 3.461 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 1 finished: saveAsHadoopDataset at Oracle2Hbase.scala:103, took 3.499762 s
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in commitJob()
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@242a209e{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-1 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-7216f12a-453a-4853-9e49-f443536006d0
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61566.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-04ce724a-69b8-4bf2-be79-d8390eec76dd
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4925ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5099ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61588.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:61588
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 61588, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:61588 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 61588, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 61588, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 61588, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@600f5704{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bac686b{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f9f3928{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2121d1f9{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1806bc4c{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f9a4401{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 338.645475 ms
 INFO main org.apache.spark.SparkContext - Starting job: foreach at Oracle2Hbase.scala:92
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (foreach at Oracle2Hbase.scala:92) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (foreach at Oracle2Hbase.scala:92)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:86), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 12.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.5 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:61588 (size: 6.5 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:86)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5778 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.770026 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.067429 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 java.lang.NullPointerException
	at org.apache.hadoop.hbase.util.Bytes.toBytes(Bytes.java:529)
	at com.antin.spark.hbaseIndex.Oracle2Hbase$$anonfun$3.apply(Oracle2Hbase.scala:88)
	at com.antin.spark.hbaseIndex.Oracle2Hbase$$anonfun$3.apply(Oracle2Hbase.scala:86)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1951)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1951)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NullPointerException
	at org.apache.hadoop.hbase.util.Bytes.toBytes(Bytes.java:529)
	at com.antin.spark.hbaseIndex.Oracle2Hbase$$anonfun$3.apply(Oracle2Hbase.scala:88)
	at com.antin.spark.hbaseIndex.Oracle2Hbase$$anonfun$3.apply(Oracle2Hbase.scala:86)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1951)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1951)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Cancelling stage 0
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (foreach at Oracle2Hbase.scala:92) failed in 0.862 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NullPointerException
	at org.apache.hadoop.hbase.util.Bytes.toBytes(Bytes.java:529)
	at com.antin.spark.hbaseIndex.Oracle2Hbase$$anonfun$3.apply(Oracle2Hbase.scala:88)
	at com.antin.spark.hbaseIndex.Oracle2Hbase$$anonfun$3.apply(Oracle2Hbase.scala:86)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1951)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1951)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 failed: foreach at Oracle2Hbase.scala:92, took 1.088744 s
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-87771433-0e08-435d-a10e-4e984382562e
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61724.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-9b9a868e-a153-4951-9d68-be0289a325ea
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4868ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5009ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61745.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:61745
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 61745, None)
 INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:61745 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 61745, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 61745, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 61745, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@600f5704{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f9f3928{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58b91d57{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1806bc4c{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69afa141{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46e64760{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 349.487797 ms
 INFO main org.apache.spark.SparkContext - Starting job: foreach at Oracle2Hbase.scala:92
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (foreach at Oracle2Hbase.scala:92) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (foreach at Oracle2Hbase.scala:92)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:86), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 12.6 KB, free 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.5 KB, free 898.5 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:61745 (size: 6.5 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:86)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5778 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 31.930201 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.836678 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1461 bytes result sent to driver
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 1599 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (foreach at Oracle2Hbase.scala:92) finished in 1.618 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: foreach at Oracle2Hbase.scala:92, took 1.870627 s
 INFO dispatcher-event-loop-1 org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 10.0.1.32:61745 in memory (size: 6.5 KB, free: 898.5 MB)
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:100
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 1 (saveAsHadoopDataset at Oracle2Hbase.scala:100) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:100)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:86), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 99.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 10.0.1.32:61745 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:86)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5791 bytes)
 INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
 INFO Executor task launch worker for task 1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 1 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0xa3503dd connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO Executor task launch worker for task 1 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0xa3503dd0x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 1-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.83/192.168.14.83:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 1-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.83/192.168.14.83:2181, initiating session
 INFO Executor task launch worker for task 1-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.83/192.168.14.83:2181, sessionid = 0x15d5d920f2b0101, negotiated timeout = 60000
 INFO Executor task launch worker for task 1 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 1 org.apache.spark.mapred.SparkHadoopMapRedUtil - No need to commit output of task because needsTaskCommit=false: attempt_20170727165732_0001_m_000000_1
 INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 1459 bytes result sent to driver
 INFO task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 2567 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (saveAsHadoopDataset at Oracle2Hbase.scala:100) finished in 2.568 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 1 finished: saveAsHadoopDataset at Oracle2Hbase.scala:100, took 2.604408 s
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in commitJob()
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-3 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-b4c3a6fe-83a2-475d-b75a-a43f896f46a0
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61835.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-afd9b9c2-4d7e-4273-b330-be427c510636
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4688ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4842ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61856.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:61856
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 61856, None)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:61856 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 61856, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 61856, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 61856, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e1fc42f{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58b91d57{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@17092fff{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69afa141{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@643d2dae{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43982337{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-0 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-7fd40cf4-21d7-4fc1-b996-05eaea132f0b
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61917.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-0f783377-8c81-4627-b466-15e24ae80e00
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4770ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1290c49{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4921ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61938.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:61938
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 61938, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:61938 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 61938, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 61938, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 61938, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e1fc42f{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@dd2856e{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b1dc579{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@338766de{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4976085{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f631ca0{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@64469d8{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55d9b8f0{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6a9b9909{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1290c49{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-1 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-0 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-3a51f107-6acb-4bc7-845b-0bb287fe0b0e
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 61994.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-18b3ee98-4aa4-43ad-8a77-70cd987d3c59
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @5234ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5377ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62015.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:62015
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 62015, None)
 INFO dispatcher-event-loop-3 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:62015 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 62015, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 62015, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 62015, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@600f5704{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4833eff3{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56928e17{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60dd0587{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@221a2068{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e38f0b7{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 323.367697 ms
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:78
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsHadoopDataset at Oracle2Hbase.scala:78) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:78)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:72), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 99.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:62015 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:72)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5790 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 31.927787 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.875103 ms
 INFO Executor task launch worker for task 0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6526cdf8 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x6526cdf80x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 0-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.85/192.168.14.85:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.85/192.168.14.85:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.85/192.168.14.85:2181, sessionid = 0x35d5d920e9300f5, negotiated timeout = 60000
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.mapred.SparkHadoopMapRedUtil - No need to commit output of task because needsTaskCommit=false: attempt_20170727170442_0000_m_000000_0
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1546 bytes result sent to driver
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 2911 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:78) finished in 2.937 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsHadoopDataset at Oracle2Hbase.scala:78, took 3.163370 s
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in commitJob()
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-3 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-d4c21171-5ade-4652-9d65-55bd01db26d1
 INFO main org.apache.spark.SparkContext - Running Spark version 2.1.1
 INFO main org.apache.spark.SecurityManager - Changing view acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing modify acls to: Administrator
 INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
 INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
 INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
 INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 62081.
 INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
 INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
 INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-6439d8d3-2475-431b-b9c3-12449f6d9ce4
 INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 898.5 MB
 INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
 INFO main org.spark_project.jetty.util.log - Logging initialized @4682ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4823ms
 INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
 INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://10.0.1.32:4040
 INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
 INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62102.
 INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 10.0.1.32:62102
 INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 10.0.1.32, 62102, None)
 INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 10.0.1.32:62102 with 898.5 MB RAM, BlockManagerId(driver, 10.0.1.32, 62102, None)
 INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 10.0.1.32, 62102, None)
 INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 10.0.1.32, 62102, None)
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@600f5704{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/F:/CommonDevelop/hadoop/project/github/antin-spark/spark-warehouse/'.
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b0a1231{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4694f434{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@793d163b{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77f905e3{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@31142d58{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: SEHR_XMAN_EVENT
 INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: select xman_id,icd_code,diagnosis from SEHR_XMAN_EVENT where icd_code is not null and diagnosis is not null
 INFO main org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 390.40301 ms
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO main org.apache.spark.SparkContext - Starting job: saveAsHadoopDataset at Oracle2Hbase.scala:78
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (saveAsHadoopDataset at Oracle2Hbase.scala:78) with 1 output partitions
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:78)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:72), which has no missing parents
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 99.3 KB, free 898.4 MB)
 INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KB, free 898.4 MB)
 INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 10.0.1.32:62102 (size: 39.3 KB, free: 898.5 MB)
 INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at Oracle2Hbase.scala:72)
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
 INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5790 bytes)
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.818323 ms
 INFO Executor task launch worker for task 0 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.161987 ms
 INFO Executor task launch worker for task 0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x53a42a20 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x53a42a200x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 0-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.85/192.168.14.85:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.85/192.168.14.85:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.85/192.168.14.85:2181, sessionid = 0x35d5d920e9300f6, negotiated timeout = 60000
 INFO Executor task launch worker for task 0 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD - closed connection
 INFO Executor task launch worker for task 0 org.apache.spark.mapred.SparkHadoopMapRedUtil - No need to commit output of task because needsTaskCommit=false: attempt_20170727170623_0000_m_000000_0
 INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1619 bytes result sent to driver
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 13815 ms on localhost (executor driver) (1/1)
 INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
 INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (saveAsHadoopDataset at Oracle2Hbase.scala:78) finished in 13.830 s
 INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: saveAsHadoopDataset at Oracle2Hbase.scala:78, took 14.035652 s
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in commitJob()
 INFO Thread-2 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@2e807c54{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2dfe5525{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@fb6097b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://10.0.1.32:4040
 INFO dispatcher-event-loop-2 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
 INFO Thread-2 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
 INFO Thread-2 org.apache.spark.storage.BlockManager - BlockManager stopped
 INFO Thread-2 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
 INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
 INFO Thread-2 org.apache.spark.SparkContext - Successfully stopped SparkContext
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
 INFO Thread-2 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-f41acf32-d8f5-4f13-a997-baf843331b2a
 INFO main org.spark_project.jetty.util.log - Logging initialized @6609ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5853495b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@524a2ffb{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f61d591{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@332820f4{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7173ae5b{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72456279{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53a9fcfd{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21f459fc{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d192aef{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1416cf9f{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@84487f4{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@bfc14b9{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@45e1aa48{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @6758ms
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4317850d{/metrics/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a901445{/SQL,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b0b7e5a{/SQL/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@68a78f3c{/SQL/execution,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3481ff98{/SQL/execution/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30c4e352{/static/sql,null,AVAILABLE,@Spark}
 WARN main org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation - The number of partitions is reduced because the specified number of partitions is less than the difference between upper bound and lower bound. Updated number of partitions: 1; Input number of partitions: 2; Lower bound: 1; Upper bound: 2.
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
 INFO main org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
 INFO main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in setupJob()
 INFO Executor task launch worker for task 0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x4908a2d5 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x4908a2d50x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.84/192.168.14.84:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.84/192.168.14.84:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.84/192.168.14.84:2181, sessionid = 0x25d5d920e8a00fa, negotiated timeout = 60000
 WARN main org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Output Path is null in commitJob()
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@45e1aa48{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@bfc14b9{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@84487f4{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1416cf9f{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d192aef{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@21f459fc{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@53a9fcfd{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@72456279{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7173ae5b{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@332820f4{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2f61d591{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@524a2ffb{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5853495b{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/jobs,null,UNAVAILABLE,@Spark}
 INFO main org.spark_project.jetty.util.log - Logging initialized @6318ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5496c165{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51a8313b{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a03d65c{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6642dc5a{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@43da41e{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@148c7c4b{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2009f9b0{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50d951e7{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39ad12b6{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4eb45fec{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@211febf3{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bd3d05e{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6aba5d30{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@61d34b4{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@588307f7{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7df76d99{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@459cfcca{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2acbc859{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ab7ce48{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c6aed22{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e322ec9{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7acfb656{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e5ee2c9{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@55a609dd{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4afd21c6{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@528bf457{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @6497ms
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ae202c6{/metrics/json,null,AVAILABLE,@Spark}
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x22aee519 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x22aee5190x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO main-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.85/192.168.14.85:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.85/192.168.14.85:2181, initiating session
 INFO main-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.85/192.168.14.85:2181, sessionid = 0x35d8429c41d0020, negotiated timeout = 60000
 INFO main org.apache.hadoop.hbase.util.RegionSizeCalculator - Calculating region sizes for table "hpor:sehr_xman".
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing master protocol: MasterService
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x35d8429c41d0020
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x35d8429c41d0020 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1a58b730 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x1a58b7300x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.83/192.168.14.83:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.83/192.168.14.83:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.83/192.168.14.83:2181, sessionid = 0x15d8429c5450016, negotiated timeout = 60000
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.mapreduce.TableInputFormatBase - Input split length: 153 M bytes.
 INFO Executor task launch worker for task 0 org.elasticsearch.hadoop.util.Version - Elasticsearch Hadoop v5.4.3 [699b4061f8]
 INFO Executor task launch worker for task 0 org.elasticsearch.spark.rdd.EsRDDWriter - Writing to [hpor:name_xmanid_index/person]
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x15d8429c5450016
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Session: 0x15d8429c5450016 closed
 INFO Executor task launch worker for task 0-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.88:9200] returned Bad Request(400) - object mapping for [Z34] tried to parse field [Z34] as object, but found a concrete value; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.88:9200] returned Bad Request(400) - object mapping for [Z34] tried to parse field [Z34] as object, but found a concrete value; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@528bf457{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4afd21c6{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@55a609dd{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2e5ee2c9{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7acfb656{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@e322ec9{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2c6aed22{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6ab7ce48{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2acbc859{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@459cfcca{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7df76d99{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@588307f7{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@61d34b4{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6aba5d30{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3bd3d05e{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@211febf3{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4eb45fec{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@39ad12b6{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@50d951e7{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2009f9b0{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@148c7c4b{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@43da41e{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6642dc5a{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2a03d65c{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@51a8313b{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5496c165{/jobs,null,UNAVAILABLE,@Spark}
 INFO main org.spark_project.jetty.util.log - Logging initialized @5024ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b835727{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@13da7ab0{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c8662ac{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@260ff5b7{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3724b43e{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77eb5790{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@68e7c8c3{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@34acbc60{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5168ms
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26fb4d06{/metrics/json,null,AVAILABLE,@Spark}
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5df2023c connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x5df2023c0x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO main-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.84/192.168.14.84:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.84/192.168.14.84:2181, initiating session
 INFO main-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.84/192.168.14.84:2181, sessionid = 0x25d8429c4090046, negotiated timeout = 60000
 INFO main org.apache.hadoop.hbase.util.RegionSizeCalculator - Calculating region sizes for table "hpor:sehr_xman".
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing master protocol: MasterService
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x25d8429c4090046
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x25d8429c4090046 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x4aa5ac3d connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x4aa5ac3d0x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.83/192.168.14.83:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.83/192.168.14.83:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.83/192.168.14.83:2181, sessionid = 0x15d8429c5450017, negotiated timeout = 60000
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.mapreduce.TableInputFormatBase - Input split length: 186 M bytes.
 INFO Executor task launch worker for task 0 org.elasticsearch.hadoop.util.Version - Elasticsearch Hadoop v5.4.3 [699b4061f8]
 INFO Executor task launch worker for task 0 org.elasticsearch.spark.rdd.EsRDDWriter - Writing to [hpor:name_xmanid_index/person]
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Client session timed out, have not heard from server in 136782ms for sessionid 0x15d8429c5450017, closing socket connection and attempting reconnect
 WARN dispatcher-event-loop-0 org.apache.spark.HeartbeatReceiver - Removing executor driver with no recent heartbeats: 145669 ms exceeds timeout 120000 ms
 ERROR dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSchedulerImpl - Lost executor driver on localhost: Executor heartbeat timed out after 145669 ms
 WARN dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): ExecutorLostFailure (executor driver exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 145669 ms
 ERROR dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 WARN kill-executor-thread org.apache.spark.SparkContext - Killing executors is only supported in coarse-grained mode
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.84/192.168.14.84:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.84/192.168.14.84:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Unable to reconnect to ZooKeeper service, session 0x15d8429c5450017 has expired, closing socket connection
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@34acbc60{HTTP/1.1}{0.0.0.0:4040}
 ERROR driver-heartbeater org.apache.spark.storage.BlockManager - Failed to report broadcast_1_piece0 to master; giving up.
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 WARN Executor task launch worker for task 0-EventThread org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - This client just lost it's session with ZooKeeper, closing it. It will be recreated next time someone needs it
 org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:606)
	at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:517)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
INFO Executor task launch worker for task 0-EventThread org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x15d8429c5450017
 INFO Executor task launch worker for task 0-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@ef1695a{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@238bfd6c{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@319c3a25{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@68e7c8c3{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@77eb5790{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3724b43e{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@260ff5b7{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2c8662ac{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@13da7ab0{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@b835727{/jobs,null,UNAVAILABLE,@Spark}
 ERROR dispatcher-event-loop-1 org.apache.spark.scheduler.LiveListenerBus - SparkListenerBus has already stopped! Dropping event SparkListenerBlockManagerAdded(1501224577116,BlockManagerId(driver, 10.0.1.32, 56216, None),942145536)
 ERROR dispatcher-event-loop-2 org.apache.spark.scheduler.LiveListenerBus - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.0.1.32, 56216, None),broadcast_0_piece0,StorageLevel(memory, 1 replicas),32081,0))
 ERROR dispatcher-event-loop-2 org.apache.spark.scheduler.LiveListenerBus - SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 10.0.1.32, 56216, None),broadcast_1_piece0,StorageLevel(memory, 1 replicas),2123,0))
 INFO main org.spark_project.jetty.util.log - Logging initialized @4848ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b835727{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@13da7ab0{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c8662ac{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@260ff5b7{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3724b43e{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77eb5790{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@68e7c8c3{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@34acbc60{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5091ms
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2aaf152b{/metrics/json,null,AVAILABLE,@Spark}
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x60f662bd connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x60f662bd0x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO main-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.85/192.168.14.85:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.85/192.168.14.85:2181, initiating session
 INFO main-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.85/192.168.14.85:2181, sessionid = 0x35d8429c41d0022, negotiated timeout = 60000
 INFO main org.apache.hadoop.hbase.util.RegionSizeCalculator - Calculating region sizes for table "hpor:sehr_xman".
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing master protocol: MasterService
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x35d8429c41d0022
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x35d8429c41d0022 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1ee8dbd connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x1ee8dbd0x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.84/192.168.14.84:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.84/192.168.14.84:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.84/192.168.14.84:2181, sessionid = 0x25d8429c4090047, negotiated timeout = 60000
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.mapreduce.TableInputFormatBase - Input split length: 186 M bytes.
 INFO Executor task launch worker for task 0 org.elasticsearch.hadoop.util.Version - Elasticsearch Hadoop v5.4.3 [699b4061f8]
 INFO Executor task launch worker for task 0 org.elasticsearch.spark.rdd.EsRDDWriter - Writing to [hpor:name_xmanid_index/person]
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x25d8429c4090047
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Session: 0x25d8429c4090047 closed
 INFO Executor task launch worker for task 0-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.90:9200] returned Bad Request(400) - Limit of total fields [1000] in index [hpor:name_xmanid_index] has been exceeded; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.90:9200] returned Bad Request(400) - Limit of total fields [1000] in index [hpor:name_xmanid_index] has been exceeded; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@34acbc60{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@ef1695a{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@238bfd6c{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@319c3a25{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@68e7c8c3{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@77eb5790{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3724b43e{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@260ff5b7{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2c8662ac{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@13da7ab0{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@b835727{/jobs,null,UNAVAILABLE,@Spark}
 INFO main org.spark_project.jetty.util.log - Logging initialized @4502ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52d6cd34{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@715d6168{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b2faa6{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6428591a{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7397c6{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1abfe081{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a685eba{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c2e3264{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@107f4980{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75a118e6{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1d540566{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6014a9ba{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@acdcf71{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77d680e6{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a14c44f{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f08fdce{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6bda1d19{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@28c86134{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4492eede{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cbc8d0f{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37b57b54{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5c1f6d57{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f288c14{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6794ac0b{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7be71476{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@61a1ea2c{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4660ms
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bbf6abe{/metrics/json,null,AVAILABLE,@Spark}
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x27261190 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x272611900x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO main-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.83/192.168.14.83:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.83/192.168.14.83:2181, initiating session
 INFO main-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.83/192.168.14.83:2181, sessionid = 0x15d8429c5450018, negotiated timeout = 60000
 INFO main org.apache.hadoop.hbase.util.RegionSizeCalculator - Calculating region sizes for table "hpor:sehr_xman".
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing master protocol: MasterService
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x15d8429c5450018
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x15d8429c5450018 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x74a0d496 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x74a0d4960x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.84/192.168.14.84:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.84/192.168.14.84:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.84/192.168.14.84:2181, sessionid = 0x25d8429c4090048, negotiated timeout = 60000
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.mapreduce.TableInputFormatBase - Input split length: 186 M bytes.
 INFO Executor task launch worker for task 0 org.elasticsearch.hadoop.util.Version - Elasticsearch Hadoop v5.4.3 [699b4061f8]
 INFO Executor task launch worker for task 0 org.elasticsearch.spark.rdd.EsRDDWriter - Writing to [hpor:name_xmanid_index/person]
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x25d8429c4090048
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Session: 0x25d8429c4090048 closed
 INFO Executor task launch worker for task 0-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.88:9200] returned Bad Request(400) - object mapping for [Z34] tried to parse field [Z34] as object, but found a concrete value; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.88:9200] returned Bad Request(400) - object mapping for [Z34] tried to parse field [Z34] as object, but found a concrete value; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@61a1ea2c{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7be71476{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6794ac0b{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@f288c14{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5c1f6d57{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@37b57b54{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@cbc8d0f{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4492eede{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@28c86134{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6bda1d19{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@f08fdce{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4a14c44f{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@77d680e6{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@acdcf71{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6014a9ba{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1d540566{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@75a118e6{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@107f4980{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@c2e3264{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2a685eba{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@1abfe081{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7397c6{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6428591a{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b2faa6{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@715d6168{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@52d6cd34{/jobs,null,UNAVAILABLE,@Spark}
 INFO main org.spark_project.jetty.util.log - Logging initialized @5094ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c8662ac{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@260ff5b7{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3724b43e{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77eb5790{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@68e7c8c3{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@36061cf3{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5270ms
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32b0876c{/metrics/json,null,AVAILABLE,@Spark}
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x224e6e88 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x224e6e880x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO main-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.84/192.168.14.84:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.84/192.168.14.84:2181, initiating session
 INFO main-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.84/192.168.14.84:2181, sessionid = 0x25d8429c4090049, negotiated timeout = 60000
 INFO main org.apache.hadoop.hbase.util.RegionSizeCalculator - Calculating region sizes for table "hpor:sehr_xman".
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing master protocol: MasterService
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x25d8429c4090049
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x25d8429c4090049 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7c95357 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x7c953570x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 0-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.85/192.168.14.85:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.85/192.168.14.85:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.85:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.85/192.168.14.85:2181, sessionid = 0x35d8429c41d0023, negotiated timeout = 60000
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.mapreduce.TableInputFormatBase - Input split length: 186 M bytes.
 INFO Executor task launch worker for task 0 org.elasticsearch.hadoop.util.Version - Elasticsearch Hadoop v5.4.3 [699b4061f8]
 INFO Executor task launch worker for task 0 org.elasticsearch.spark.rdd.EsRDDWriter - Writing to [hpor:name_xmanid_index/person]
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x35d8429c41d0023
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Session: 0x35d8429c41d0023 closed
 INFO Executor task launch worker for task 0-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.88:9200] returned Bad Request(400) - object mapping for [Z34] tried to parse field [Z34] as object, but found a concrete value; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.88:9200] returned Bad Request(400) - object mapping for [Z34] tried to parse field [Z34] as object, but found a concrete value; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@36061cf3{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@ef1695a{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@238bfd6c{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@319c3a25{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@68e7c8c3{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@77eb5790{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3724b43e{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@260ff5b7{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2c8662ac{/jobs,null,UNAVAILABLE,@Spark}
 INFO main org.spark_project.jetty.util.log - Logging initialized @5752ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c8662ac{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@260ff5b7{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3724b43e{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77eb5790{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@68e7c8c3{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@528bf457{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @5931ms
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5349b246{/metrics/json,null,AVAILABLE,@Spark}
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0xa95cb11 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\Program Files\Java\jdk1.8.0_51\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;D:\Program Files\Java\jdk1.8.0_51\bin;E:\Mysql\soft\MyCAT\mycat\bin;C:\ProgramData\Oracle\Java\javapath;D:\MySoftware\ant\apache-ant-1.9.6\bin;D:\Program Files\Java\jdk1.7.0_45\bin;E:\Ambari\hadoop-home\hadoop2.7\hdp\bin;D:\MySoftware\instantclient_plsql\instantclient-basic-nt-12.1.0.2.0\instantclient_12_1\NETWORD\ADMIN;SIMPLIFIED CHINESE_CHINA.ZHS16GBK\;D:\MySoftware\maven\apache-maven-3.0.5\bin;D:\Program Files\CollabNet\Subversion Client;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;D:\Program Files\TortoiseSVN\bin;D:\Program Files\SlikSvn\bin;C:\Program Files\Microsoft SQL Server\120\Tools\Binn\;D:\Program Files\VisualSVN Server\bin;D:\Program Files (x86)\scala\bin;D:\ProgramData\Anaconda2;D:\Program Files (x86)\scala\bin;.
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 7
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.1
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\Administrator
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=F:\CommonDevelop\hadoop\project\github\antin-spark
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0xa95cb110x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO main-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.84/192.168.14.84:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.84/192.168.14.84:2181, initiating session
 INFO main-SendThread(192.168.14.84:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.84/192.168.14.84:2181, sessionid = 0x25d8429c409004a, negotiated timeout = 60000
 INFO main org.apache.hadoop.hbase.util.RegionSizeCalculator - Calculating region sizes for table "hpor:sehr_xman".
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing master protocol: MasterService
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x25d8429c409004a
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x25d8429c409004a closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x67bd74b9 connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181 sessionTimeout=90000 watcher=hconnection-0x67bd74b90x0, quorum=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181, baseZNode=/hbase-unsecure
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 192.168.14.83/192.168.14.83:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 192.168.14.83/192.168.14.83:2181, initiating session
 INFO Executor task launch worker for task 0-SendThread(192.168.14.83:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 192.168.14.83/192.168.14.83:2181, sessionid = 0x15d8429c5450019, negotiated timeout = 60000
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.mapreduce.TableInputFormatBase - Input split length: 186 M bytes.
 INFO Executor task launch worker for task 0 org.elasticsearch.hadoop.util.Version - Elasticsearch Hadoop v5.4.3 [699b4061f8]
 INFO Executor task launch worker for task 0 org.elasticsearch.spark.rdd.EsRDDWriter - Writing to [hpor:name_xmanid_index/person]
 INFO Executor task launch worker for task 0 org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x15d8429c5450019
 INFO Executor task launch worker for task 0 org.apache.zookeeper.ZooKeeper - Session: 0x15d8429c5450019 closed
 INFO Executor task launch worker for task 0-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 ERROR Executor task launch worker for task 0 org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
 org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.88:9200] returned Bad Request(400) - object mapping for [Z34] tried to parse field [Z34] as object, but found a concrete value; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: Found unrecoverable error [192.168.14.88:9200] returned Bad Request(400) - object mapping for [Z34] tried to parse field [Z34] as object, but found a concrete value; Bailing out..
	at org.elasticsearch.hadoop.rest.RestClient.processBulkResponse(RestClient.java:251)
	at org.elasticsearch.hadoop.rest.RestClient.bulk(RestClient.java:203)
	at org.elasticsearch.hadoop.rest.RestRepository.tryFlush(RestRepository.java:220)
	at org.elasticsearch.hadoop.rest.RestRepository.flush(RestRepository.java:242)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:196)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:159)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

 ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
 INFO Thread-2 org.spark_project.jetty.server.ServerConnector - Stopped Spark@528bf457{HTTP/1.1}{0.0.0.0:4040}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@69228e85{/jobs/job/kill,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4e1ce44{/api,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@6778aea6{/,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e15bb06{/static,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@161f6623{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@150ede8b{/executors/threadDump,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4d8286c4{/executors/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@790a251b{/executors,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3e17a0a1{/environment/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@27b45ea{/environment,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@4b3fe06e{/storage/rdd/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@199bc830{/storage/rdd,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7139bd31{/storage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7487b142{/storage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@81b5db0{/stages/pool/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@58860997{/stages/pool,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@ef1695a{/stages/stage/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@238bfd6c{/stages/stage,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@319c3a25{/stages/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@68e7c8c3{/stages,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@77eb5790{/jobs/job/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@3724b43e{/jobs/job,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@260ff5b7{/jobs/json,null,UNAVAILABLE,@Spark}
 INFO Thread-2 org.spark_project.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@2c8662ac{/jobs,null,UNAVAILABLE,@Spark}
 INFO main org.spark_project.jetty.util.log - Logging initialized @4657ms
 INFO main org.spark_project.jetty.server.Server - jetty-9.2.z-SNAPSHOT
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c8662ac{/jobs,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@260ff5b7{/jobs/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3724b43e{/jobs/job,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@77eb5790{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@68e7c8c3{/stages,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319c3a25{/stages/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@238bfd6c{/stages/stage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ef1695a{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58860997{/stages/pool,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@81b5db0{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7487b142{/storage,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7139bd31{/storage/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@199bc830{/storage/rdd,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4b3fe06e{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@27b45ea{/environment,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e17a0a1{/environment/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@790a251b{/executors,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4d8286c4{/executors/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@150ede8b{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@161f6623{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e15bb06{/static,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6778aea6{/,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4e1ce44{/api,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69228e85{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a7cc52c{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO main org.spark_project.jetty.server.ServerConnector - Started Spark@36061cf3{HTTP/1.1}{0.0.0.0:4040}
 INFO main org.spark_project.jetty.server.Server - Started @4798ms
 INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32b0876c{/metrics/json,null,AVAILABLE,@Spark}
 WARN main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - The short-circuit local reads feature cannot be used because UNIX Domain sockets are not available on Windows.
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x52285a5f connecting to ZooKeeper ensemble=192.168.14.85:2181,192.168.14.83:2181,192.168.14.84:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=YF-changjinJ.zysoft.com.cn
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_51
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\Program Files\Java\jdk1.8.0_51\jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\Program Files\Java\jdk1.8.0_51\jre\lib\charsets.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\deploy.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\access-bridge-64.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\cldrdata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\dnsns.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jaccess.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\jfxrt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\localedata.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\nashorn.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunec.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunjce_provider.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunmscapi.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\sunpkcs11.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\ext\zipfs.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\javaws.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jce.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfr.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jfxswt.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\jsse.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\management-agent.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\plugin.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\resources.jar;D:\Program Files\Java\jdk1.8.0_51\jre\lib\rt.jar;F:\CommonDevelop\hadoop\project\github\antin-spark\antin-test\target\classes;F:\CommonDevelop\maven\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-core_2.11\2.1.1\spark-core_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7-tests.jar;F:\CommonDevelop\maven\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;F:\CommonDevelop\maven\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;F:\CommonDevelop\maven\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;F:\CommonDevelop\maven\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-launcher_2.11\2.1.1\spark-launcher_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-common_2.11\2.1.1\spark-network-common_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-network-shuffle_2.11\2.1.1\spark-network-shuffle_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-unsafe_2.11\2.1.1\spark-unsafe_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\net\java\dev\jets3t\jets3t\0.7.1\jets3t-0.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-recipes\2.4.0\curator-recipes-2.4.0.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-framework\2.4.0\curator-framework-2.4.0.jar;F:\CommonDevelop\maven\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;F:\CommonDevelop\maven\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;F:\CommonDevelop\maven\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;F:\CommonDevelop\maven\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;F:\CommonDevelop\maven\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;F:\CommonDevelop\maven\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;F:\CommonDevelop\maven\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;F:\CommonDevelop\maven\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;F:\CommonDevelop\maven\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scalap\2.11.0\scalap-2.11.0.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-compiler\2.11.0\scala-compiler-2.11.0.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-client\2.22.2\jersey-client-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\ws\rs\javax.ws.rs-api\2.0.1\javax.ws.rs-api-2.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-api\2.4.0-b34\hk2-api-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-utils\2.4.0-b34\hk2-utils-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.4.0-b34\aopalliance-repackaged-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\external\javax.inject\2.4.0-b34\javax.inject-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\hk2-locator\2.4.0-b34\hk2-locator-2.4.0-b34.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-common\2.22.2\jersey-common-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\annotation\javax.annotation-api\1.2\javax.annotation-api-1.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\bundles\repackaged\jersey-guava\2.22.2\jersey-guava-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\hk2\osgi-resource-locator\1.0.1\osgi-resource-locator-1.0.1.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\core\jersey-server\2.22.2\jersey-server-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\media\jersey-media-jaxb\2.22.2\jersey-media-jaxb-2.22.2.jar;F:\CommonDevelop\maven\repository\javax\validation\validation-api\1.1.0.Final\validation-api-1.1.0.Final.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.22.2\jersey-container-servlet-2.22.2.jar;F:\CommonDevelop\maven\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.22.2\jersey-container-servlet-core-2.22.2.jar;F:\CommonDevelop\maven\repository\io\netty\netty-all\4.0.42.Final\netty-all-4.0.42.Final.jar;F:\CommonDevelop\maven\repository\io\netty\netty\3.8.0.Final\netty-3.8.0.Final.jar;F:\CommonDevelop\maven\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;F:\CommonDevelop\maven\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;F:\CommonDevelop\maven\repository\org\scala-lang\scala-reflect\2.11.7\scala-reflect-2.11.7.jar;F:\CommonDevelop\maven\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;F:\CommonDevelop\maven\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;F:\CommonDevelop\maven\repository\oro\oro\2.0.8\oro-2.0.8.jar;F:\CommonDevelop\maven\repository\net\razorvine\pyrolite\4.13\pyrolite-4.13.jar;F:\CommonDevelop\maven\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-tags_2.11\2.1.1\spark-tags_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;F:\CommonDevelop\maven\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-client\2.7.3\hadoop-client-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-common\2.7.3\hadoop-common-2.7.3.jar;F:\CommonDevelop\maven\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;F:\CommonDevelop\maven\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;F:\CommonDevelop\maven\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;F:\CommonDevelop\maven\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;F:\CommonDevelop\maven\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;F:\CommonDevelop\maven\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\curator\curator-client\2.7.1\curator-client-2.7.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-hdfs\2.7.3\hadoop-hdfs-2.7.3.jar;F:\CommonDevelop\maven\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;F:\CommonDevelop\maven\repository\xml-apis\xml-apis\1.3.04\xml-apis-1.3.04.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.7.3\hadoop-mapreduce-client-app-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.7.3\hadoop-mapreduce-client-common-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.7.3\hadoop-mapreduce-client-shuffle-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-api\2.7.3\hadoop-yarn-api-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.7.3\hadoop-mapreduce-client-core-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.7.3\hadoop-mapreduce-client-jobclient-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-annotations\2.7.3\hadoop-annotations-2.7.3.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sql_2.11\2.1.1\spark-sql_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-sketch_2.11\2.1.1\spark-sketch_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-catalyst_2.11\2.1.1\spark-catalyst_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;F:\CommonDevelop\maven\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;F:\CommonDevelop\maven\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-column\1.8.1\parquet-column-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-common\1.8.1\parquet-common-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-encoding\1.8.1\parquet-encoding-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-hadoop\1.8.1\parquet-hadoop-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-format\2.3.0-incubating\parquet-format-2.3.0-incubating.jar;F:\CommonDevelop\maven\repository\org\apache\parquet\parquet-jackson\1.8.1\parquet-jackson-1.8.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming_2.11\2.1.1\spark-streaming_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-streaming-kafka_2.11\1.6.1\spark-streaming-kafka_2.11-1.6.1.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka_2.11\0.8.2.1\kafka_2.11-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.2\scala-parser-combinators_2.11-1.0.2.jar;F:\CommonDevelop\maven\repository\com\101tec\zkclient\0.3\zkclient-0.3.jar;F:\CommonDevelop\maven\repository\org\apache\kafka\kafka-clients\0.8.2.1\kafka-clients-0.8.2.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-yarn_2.11\2.1.1\spark-yarn_2.11-2.1.1.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-common\2.2.0\hadoop-yarn-common-2.2.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\extensions\guice-servlet\3.0\guice-servlet-3.0.jar;F:\CommonDevelop\maven\repository\com\google\inject\guice\3.0\guice-3.0.jar;F:\CommonDevelop\maven\repository\javax\inject\javax.inject\1\javax.inject-1.jar;F:\CommonDevelop\maven\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-web-proxy\2.2.0\hadoop-yarn-server-web-proxy-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-server-common\2.2.0\hadoop-yarn-server-common-2.2.0.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-yarn-client\2.2.0\hadoop-yarn-client-2.2.0.jar;F:\CommonDevelop\maven\repository\mysql\mysql-connector-java\5.1.38\mysql-connector-java-5.1.38.jar;F:\CommonDevelop\maven\repository\com\zoe\ojdbc6\20160518\ojdbc6-20160518.jar;F:\CommonDevelop\maven\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;F:\CommonDevelop\maven\repository\jline\jline\0.9.94\jline-0.9.94.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-protocol\1.1.2\hbase-protocol-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-annotations\1.1.2\hbase-annotations-1.1.2.jar;D:\Program Files\Java\jdk1.8.0_51\lib\tools.jar;F:\CommonDevelop\maven\repository\com\google\guava\guava\12.0.1\guava-12.0.1.jar;F:\CommonDevelop\maven\repository\commons-logging\commons-logging\1.2\commons-logging-1.2.jar;F:\CommonDevelop\maven\repository\commons-codec\commons-codec\1.9\commons-codec-1.9.jar;F:\CommonDevelop\maven\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;F:\CommonDevelop\maven\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;F:\CommonDevelop\maven\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;F:\CommonDevelop\maven\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;F:\CommonDevelop\maven\repository\org\apache\htrace\htrace-core\3.1.0-incubating\htrace-core-3.1.0-incubating.jar;F:\CommonDevelop\maven\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;F:\CommonDevelop\maven\repository\junit\junit\4.11\junit-4.11.jar;F:\CommonDevelop\maven\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-client\1.1.2\hbase-client-1.1.2.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\jruby\jcodings\jcodings\1.0.8\jcodings-1.0.8.jar;F:\CommonDevelop\maven\repository\org\jruby\joni\joni\2.1.2\joni-2.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hadoop\hadoop-auth\2.5.1\hadoop-auth-2.5.1.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpclient\4.2.5\httpclient-4.2.5.jar;F:\CommonDevelop\maven\repository\org\apache\httpcomponents\httpcore\4.2.4\httpcore-4.2.4.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-server\1.1.2\hbase-server-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-procedure\1.1.2\hbase-procedure-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-common\1.1.2\hbase-common-1.1.2-tests.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-prefix-tree\1.1.2\hbase-prefix-tree-1.1.2.jar;F:\CommonDevelop\maven\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop-compat\1.1.2\hbase-hadoop-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\org\apache\hbase\hbase-hadoop2-compat\1.1.2\hbase-hadoop2-compat-1.1.2.jar;F:\CommonDevelop\maven\repository\com\yammer\metrics\metrics-core\2.2.0\metrics-core-2.2.0.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;F:\CommonDevelop\maven\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;F:\CommonDevelop\maven\repository\asm\asm\3.1\asm-3.1.jar;F:\CommonDevelop\maven\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-math\2.2\commons-math-2.2.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jetty-sslengine\6.1.26\jetty-sslengine-6.1.26.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;F:\CommonDevelop\maven\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;F:\CommonDevelop\maven\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-compiler\5.5.23\jasper-compiler-5.5.23.jar;F:\CommonDevelop\maven\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;F:\CommonDevelop\maven\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;F:\CommonDevelop\maven\repository\org\jamon\jamon-runtime\2.3.1\jamon-runtime-2.3.1.jar;F:\CommonDevelop\maven\repository\com\lmax\disruptor\3.3.0\disruptor-3.3.0.jar;F:\CommonDevelop\maven\repository\com\beust\jcommander\1.48\jcommander-1.48.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-core\0.8.0\deeplearning4j-core-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-modelimport\0.8.0\deeplearning4j-modelimport-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp\1.3.2\javacpp-1.3.2.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5-platform\1.10.0-patch1-1.3\hdf5-platform-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\hdf5\1.10.0-patch1-1.3\hdf5-1.10.0-patch1-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nn\0.8.0\deeplearning4j-nn-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\commons\commons-compress\1.8\commons-compress-1.8.jar;F:\CommonDevelop\maven\repository\org\tukaani\xz\1.5\xz-1.5.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-api\0.8.0\nd4j-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-buffer\0.8.0\nd4j-buffer-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-context\0.8.0\nd4j-context-0.8.0.jar;F:\CommonDevelop\maven\repository\net\ericaro\neoitertools\1.0.0\neoitertools-1.0.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\jackson\0.8.0\jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\yaml\snakeyaml\1.12\snakeyaml-1.12.jar;F:\CommonDevelop\maven\repository\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;F:\CommonDevelop\maven\repository\org\json\json\20131018\json-20131018.jar;F:\CommonDevelop\maven\repository\org\projectlombok\lombok\1.16.10\lombok-1.16.10.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-nd4j-common\0.8.0\datavec-nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-data-image\0.8.0\datavec-data-image-0.8.0.jar;F:\CommonDevelop\maven\repository\com\github\jai-imageio\jai-imageio-core\1.3.0\jai-imageio-core-1.3.0.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-jpeg\3.1.1\imageio-jpeg-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-core\3.1.1\imageio-core-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-metadata\3.1.1\imageio-metadata-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-lang\3.1.1\common-lang-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-io\3.1.1\common-io-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\common\common-image\3.1.1\common-image-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-tiff\3.1.1\imageio-tiff-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-psd\3.1.1\imageio-psd-3.1.1.jar;F:\CommonDevelop\maven\repository\com\twelvemonkeys\imageio\imageio-bmp\3.1.1\imageio-bmp-3.1.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacv\1.3.1\javacv-1.3.1.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\ffmpeg\3.2.1-1.3\ffmpeg-3.2.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flycapture\2.9.3.43-1.3\flycapture-2.9.3.43-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libdc1394\2.2.4-1.3\libdc1394-2.2.4-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect\0.5.3-1.3\libfreenect-0.5.3-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\libfreenect2\0.2.0-1.3\libfreenect2-0.2.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\librealsense\1.9.6-1.3\librealsense-1.9.6-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\videoinput\0.200-1.3\videoinput-0.200-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\artoolkitplus\2.3.1-1.3\artoolkitplus-2.3.1-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\flandmark\1.07-1.3\flandmark-1.07-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv-platform\3.1.0-1.3\opencv-platform-3.1.0-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\opencv\3.1.0-1.3\opencv-3.1.0-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica-platform\1.73-1.3\leptonica-platform-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\leptonica\1.73-1.3\leptonica-1.73-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-ui-components\0.8.0\deeplearning4j-ui-components-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-platform\0.8.0\nd4j-native-platform-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas-platform\0.2.19-1.3\openblas-platform-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-arm.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-android-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-armhf.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86.jar;F:\CommonDevelop\maven\repository\org\bytedeco\javacpp-presets\openblas\0.2.19-1.3\openblas-0.2.19-1.3-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-arm.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-android-x86.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-macosx-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-windows-x86_64.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native\0.8.0\nd4j-native-0.8.0-linux-ppc64le.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-api\0.8.0\datavec-api-0.8.0.jar;F:\CommonDevelop\maven\repository\joda-time\joda-time\2.9.2\joda-time-2.9.2.jar;F:\CommonDevelop\maven\repository\org\freemarker\freemarker\2.3.23\freemarker-2.3.23.jar;F:\CommonDevelop\maven\repository\org\reflections\reflections\0.9.10\reflections-0.9.10.jar;F:\CommonDevelop\maven\repository\org\javassist\javassist\3.19.0-GA\javassist-3.19.0-GA.jar;F:\CommonDevelop\maven\repository\com\google\code\findbugs\annotations\2.0.1\annotations-2.0.1.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-common\0.8.0\nd4j-common-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark_2.11\0.8.0_spark_2\dl4j-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\datavec\datavec-spark_2.11\0.8.0_spark_2\datavec-spark_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib_2.11\2.1.0\spark-mllib_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-graphx_2.11\2.1.0\spark-graphx_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\com\github\fommil\netlib\core\1.1.2\core-1.1.2.jar;F:\CommonDevelop\maven\repository\net\sourceforge\f2j\arpack_combined_all\0.1\arpack_combined_all-0.1.jar;F:\CommonDevelop\maven\repository\org\apache\spark\spark-mllib-local_2.11\2.1.0\spark-mllib-local_2.11-2.1.0.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze_2.11\0.12\breeze_2.11-0.12.jar;F:\CommonDevelop\maven\repository\org\scalanlp\breeze-macros_2.11\0.12\breeze-macros_2.11-0.12.jar;F:\CommonDevelop\maven\repository\net\sf\opencsv\opencsv\2.3\opencsv-2.3.jar;F:\CommonDevelop\maven\repository\com\github\rwl\jtransforms\2.4.0\jtransforms-2.4.0.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire_2.11\0.7.4\spire_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\org\spire-math\spire-macros_2.11\0.7.4\spire-macros_2.11-0.7.4.jar;F:\CommonDevelop\maven\repository\com\chuusai\shapeless_2.11\2.0.0\shapeless_2.11-2.0.0.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-model\1.2.15\pmml-model-1.2.15.jar;F:\CommonDevelop\maven\repository\org\jpmml\pmml-schema\1.2.15\pmml-schema-1.2.15.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\deeplearning4j-nlp\0.8.0\deeplearning4j-nlp-0.8.0.jar;F:\CommonDevelop\maven\repository\org\apache\directory\studio\org.apache.commons.codec\1.8\org.apache.commons.codec-1.8.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-native-api\0.8.0\nd4j-native-api-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-jackson\0.8.0\nd4j-jackson-0.8.0.jar;F:\CommonDevelop\maven\repository\org\nd4j\nd4j-base64\0.8.0\nd4j-base64-0.8.0.jar;F:\CommonDevelop\maven\repository\org\deeplearning4j\dl4j-spark-nlp_2.11\0.8.0_spark_2\dl4j-spark-nlp_2.11-0.8.0_spark_2.jar;F:\CommonDevelop\maven\repository\com\zoe\IKAnalyzer2012_u6\20170517\IKAnalyzer2012_u6-20170517.jar;F:\CommonDevelop\maven\repository\org\apache\lucene\lucene-core\3.6.0\lucene-core-3.6.0.jar;F:\CommonDevelop\maven\repository\org\elasticsearch\elasticsearch-hadoop\5.4.3\elasticsearch-hadoop-5.4.3.jar;C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.2\lib\idea_rt.jar
 